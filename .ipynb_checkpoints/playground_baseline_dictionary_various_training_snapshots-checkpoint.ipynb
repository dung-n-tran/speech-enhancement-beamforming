{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "# print(plt.style.available)\n",
    "plt.style.use(\"ggplot\")\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_MVDR(object):\n",
    "    def __init__(self, vs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vs: Source manifold array vector\n",
    "        \"\"\"\n",
    "        self.vs = vs\n",
    "        self.weights_ = None\n",
    "        \n",
    "    def _compute_weights(self, training_data):\n",
    "        n_training_samples = len(training_data)\n",
    "        n_mics, snapshot = training_data[0].shape\n",
    "        D = np.zeros((n_mics, n_training_samples), dtype=complex)\n",
    "        for i_training_sample in range(n_training_samples):\n",
    "            nv = training_data[i_training_sample]\n",
    "            Rnhat = nv.dot(nv.transpose().conjugate()) / snapshot\n",
    "            Rnhatinv = np.linalg.inv(Rnhat)\n",
    "            w = Rnhatinv.dot(self.vs) / (self.vs.transpose().conjugate().dot(Rnhatinv).dot(self.vs))\n",
    "            D[:, i_training_sample] = w.reshape(n_mics,)\n",
    "        return D\n",
    "\n",
    "    def _initialize(self, X):\n",
    "        pass\n",
    "\n",
    "    def _choose_weights(self, x):\n",
    "        n_dictionary_atoms = self.weights_.shape[1]\n",
    "        R = x.dot(x.transpose().conjugate())\n",
    "        proxy = np.diagonal(self.weights_.transpose().conjugate().dot(R).dot(self.weights_))\n",
    "        optimal_weight_index = np.argmin(proxy)\n",
    "        return self.weights_[:, optimal_weight_index]\n",
    "    \n",
    "    def fit(self, training_data):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: shape = [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        D = self._compute_weights(training_data)\n",
    "        self.weights_ = D\n",
    "        return self\n",
    "\n",
    "    def choose_weights(self, x):\n",
    "        return self._choose_weights(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Linear Array (ULA)\n",
    "n_mics = 10\n",
    "d = 0.5\n",
    "d_array = d*np.arange(-(n_mics-1)/2, (n_mics-1)/2+1).reshape(n_mics, 1)\n",
    "us = 0\n",
    "vs = np.exp(1j*2*np.pi*d_array*us)\n",
    "\n",
    "SNRs = np.arange(0, 31, 10)\n",
    "n_SNRs = len(SNRs)\n",
    "sigma_n = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_samples = 2000\n",
    "training_snapshots = [10, 100, 1000]\n",
    "sigma = 10**(20/10)\n",
    "training_noise_interference_data_various_snapshots = []\n",
    "for training_snapshot in training_snapshots:\n",
    "    training_noise_interference_data = []\n",
    "    for i_training_sample in range(n_training_samples):\n",
    "        u = np.random.uniform(0, 1)\n",
    "        vi = np.exp(1j*2*np.pi*d_array*u)\n",
    "        ii = np.sqrt(sigma/2)*np.random.randn(1, training_snapshot) + 1j*np.sqrt(sigma/2)*np.random.randn(1, training_snapshot) # interference samples\n",
    "        noise = np.sqrt(sigma_n/2)*np.random.randn(n_mics, training_snapshot) + 1j*np.sqrt(sigma_n/2)*np.random.randn(n_mics, training_snapshot) # Gaussian noise samples\n",
    "        nv = vi*ii + noise\n",
    "        training_noise_interference_data.append(nv)\n",
    "    training_noise_interference_data_various_snapshots.append(training_noise_interference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = []\n",
    "for i_training_snapshot in range(len(training_snapshots)):\n",
    "    training_noise_interference_data = training_noise_interference_data_various_snapshots[i_training_snapshot]\n",
    "    dictionary = Base_MVDR(vs)\n",
    "    dictionary.fit(training_noise_interference_data);\n",
    "    dictionaries.append(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daa8fdfc632491481a8d8cd896c0ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='SNRs', max=4, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af60f0d7c5264d5ab1bd13d149889d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Snapshots', max=9, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_trials = 200\n",
    "snapshots = np.array([10, 20, 30, 40, 60, 100, 200, 500, 1000])\n",
    "n_snapshots = len(snapshots)\n",
    "ui1 = np.random.uniform(0, 1)\n",
    "ui2 = np.random.uniform(0, 1)\n",
    "sigma_1 = 10**(20/10)\n",
    "sigma_2 = 0*10**(20/10)\n",
    "vi1 = np.exp(1j*2*np.pi*d_array*ui1)\n",
    "vi2 = np.exp(1j*2*np.pi*d_array*ui2)\n",
    "Rn = sigma_1*vi1.dot(vi1.transpose().conjugate()) + sigma_2*vi2.dot(vi2.transpose().conjugate()) + sigma_n*np.identity(n_mics)\n",
    "Rninv = np.linalg.inv(Rn)\n",
    "Wo = Rninv.dot(vs) / (vs.transpose().conjugate().dot(Rninv).dot(vs))\n",
    "\n",
    "sinr_snr_mvdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_mpdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_baseline_mpdr = np.zeros((len(training_snapshots), n_SNRs, n_snapshots))\n",
    "\n",
    "for i_SNR in tqdm_notebook(range(n_SNRs), desc=\"SNRs\"):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())\n",
    "    \n",
    "    SINRopt = ( np.real(Wo.transpose().conjugate().dot(Rs).dot(Wo)) / np.real(Wo.transpose().conjugate().dot(Rn).dot(Wo)) )[0][0]\n",
    "    \n",
    "    for i_snapshot in tqdm_notebook(range(n_snapshots), desc=\"Snapshots\", leave=False):\n",
    "        snapshot = snapshots[i_snapshot]\n",
    "        sinr_mvdr = np.zeros(n_trials)\n",
    "        sinr_mpdr = np.zeros(n_trials)\n",
    "        sinr_baseline_mpdr = np.zeros((len(training_snapshots), n_trials))\n",
    "        \n",
    "        for i_trial in range(n_trials):\n",
    "            ss = np.sqrt(sigma_s/2)*np.random.randn(1, snapshot) + 1j*np.sqrt(sigma_s/2)*np.random.randn(1, snapshot) # signal samples\n",
    "            ii1 = np.sqrt(sigma_1/2)*np.random.randn(1, snapshot) + 1j*np.sqrt(sigma_1/2)*np.random.randn(1, snapshot) # first interference samples\n",
    "            ii2 = np.sqrt(sigma_2/2)*np.random.randn(1, snapshot) + 1j*np.sqrt(sigma_1/2)*np.random.randn(1, snapshot) # second interference samples\n",
    "            nn = np.sqrt(sigma_n/2)*np.random.randn(n_mics, snapshot) + 1j*np.sqrt(sigma_n/2)*np.random.randn(n_mics, snapshot) # Gaussian noise samples\n",
    "            \n",
    "            sv = vs*ss\n",
    "            nv = vi1*ii1 + vi2*ii2 + nn\n",
    "            xx = sv + nv\n",
    "            \n",
    "            Rnhat = nv.dot(nv.transpose().conjugate()) / snapshot\n",
    "            Rxhat = xx.dot(xx.transpose().conjugate()) / snapshot\n",
    "            \n",
    "            Rnhatinv = np.linalg.inv(Rnhat)\n",
    "            Rxhatinv = np.linalg.inv(Rxhat)\n",
    "            \n",
    "            wv = Rnhatinv.dot(vs) / (vs.transpose().conjugate().dot(Rnhatinv).dot(vs))\n",
    "            wp = Rxhatinv.dot(vs) / (vs.transpose().conjugate().dot(Rxhatinv).dot(vs))\n",
    "            for i_dictionary in range(len(dictionaries)):\n",
    "                dictionary = dictionaries[i_dictionary]\n",
    "                w_baseline_p = dictionary.choose_weights(xx)\n",
    "                sinr_baseline_mpdr[i_dictionary, i_trial] = np.real(w_baseline_p.transpose().conjugate().dot(Rs).dot(w_baseline_p)) / np.real(w_baseline_p.transpose().conjugate().dot(Rn).dot(w_baseline_p)) / SINRopt\n",
    "                \n",
    "            sinr_mvdr[i_trial] = np.real(wv.transpose().conjugate().dot(Rs).dot(wv)) / np.real(wv.transpose().conjugate().dot(Rn).dot(wv)) / SINRopt\n",
    "            sinr_mpdr[i_trial] = np.real(wp.transpose().conjugate().dot(Rs).dot(wp)) / np.real(wp.transpose().conjugate().dot(Rn).dot(wp)) / SINRopt\n",
    "            \n",
    "        sinr_snr_mvdr[i_SNR, i_snapshot] = np.sum(sinr_mvdr) / n_trials\n",
    "        sinr_snr_mpdr[i_SNR, i_snapshot] = np.sum(sinr_mpdr) / n_trials\n",
    "        for i_dictionary in range(len(dictionaries)):\n",
    "            sinr_snr_baseline_mpdr[i_dictionary, i_SNR, i_snapshot] = np.sum(sinr_baseline_mpdr[i_dictionary, :]) / n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_SNR in range(n_SNRs):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())\n",
    "    \n",
    "    SINRopt = ( np.real(Wo.transpose().conjugate().dot(Rs).dot(Wo)) / np.real(Wo.transpose().conjugate().dot(Rn).dot(Wo)) )[0][0]\n",
    "    fig = plt.figure(figsize=(9, 6)); ax = fig.add_subplot(111)\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mvdr[i_SNR, :]*SINRopt), marker=\"o\", label=\"MVDR\")\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mpdr[i_SNR, :]*SINRopt), marker=\"*\", label=\"MPDR\")\n",
    "    for i_training_snapshot in range(len(training_snapshots)):\n",
    "        ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mpdr[i_training_snapshot, i_SNR, :]*SINRopt), \n",
    "                    label=\"Baseline - {} training snapshots\".format(training_snapshots[i_training_snapshot]))\n",
    "    ax.set_xlim(10, 1000); ax.set_ylim(-10, 45)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_xlabel(\"Number of snapshots\")\n",
    "    ax.set_ylabel(r\"$SINR_0$ [dB]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-p36",
   "language": "python",
   "name": "tensorflow-gpu-p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
