{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "# print(plt.style.available)\n",
    "plt.style.use(\"ggplot\")\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_linear_array(n_mics, spacing):\n",
    "    return spacing*np.arange(-(n_mics-1)/2, (n_mics-1)/2+1).reshape(1, n_mics)\n",
    "\n",
    "def compute_MVDR_weight(source_steering_vector, signals):\n",
    "    snapshot = signals.shape[1]\n",
    "    sample_covariance_matrix = signals.dot(signals.transpose().conjugate()) / snapshot\n",
    "    inverse_sample_covariance_matrix = np.linalg.inv(sample_covariance_matrix)\n",
    "    normalization_factor = (source_steering_vector.transpose().conjugate().dot(inverse_sample_covariance_matrix).dot(source_steering_vector))\n",
    "    weight = inverse_sample_covariance_matrix.dot(source_steering_vector) / normalization_factor\n",
    "    return weight\n",
    "\n",
    "def compute_steering_vector_ULA(u, microphone_array):\n",
    "    return np.exp(1j*2*np.pi*microphone_array.geometry*u).reshape((microphone_array.n_mics, 1))\n",
    "\n",
    "def generate_gaussian_samples(power, shape):\n",
    "    return np.sqrt(power/2)*np.random.randn(shape[0], shape[1]) + 1j*np.sqrt(power/2)*np.random.randn(shape[0], shape[1]); # signal samples\n",
    "\n",
    "class MicrophoneArray():\n",
    "    def __init__(self, array_geometry):\n",
    "        self.dim = array_geometry.shape[0]\n",
    "        self.n_mics = array_geometry.shape[1]\n",
    "        self.geometry = array_geometry\n",
    "\n",
    "    \n",
    "        \n",
    "class BaseDLBeamformer(object):\n",
    "    def __init__(self, vs, bf_type=\"MVDR\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vs: Source manifold array vector\n",
    "        bf_type: Type of beamformer\n",
    "        \"\"\"\n",
    "        self.vs = vs\n",
    "        self.bf_type = bf_type\n",
    "        self.weights_ = None\n",
    "        \n",
    "    def _compute_weights(self, training_data):\n",
    "        n_training_samples = len(training_data)\n",
    "        n_mics, snapshot = training_data[0].shape\n",
    "        D = np.zeros((n_mics, n_training_samples), dtype=complex)\n",
    "        for i_training_sample in range(n_training_samples):\n",
    "            nv = training_data[i_training_sample]\n",
    "            if self.bf_type == \"MVDR\":\n",
    "                w = compute_MVDR_weight(vs, nv)\n",
    "            D[:, i_training_sample] = w.reshape(n_mics,)\n",
    "        return D\n",
    "\n",
    "    def _initialize(self, X):\n",
    "        pass\n",
    "\n",
    "    def _choose_weights(self, x):\n",
    "        n_dictionary_atoms = self.weights_.shape[1]\n",
    "        R = x.dot(x.transpose().conjugate())\n",
    "        proxy = np.diagonal(self.weights_.transpose().conjugate().dot(R).dot(self.weights_))\n",
    "        optimal_weight_index = np.argmin(proxy)\n",
    "        return self.weights_[:, optimal_weight_index]\n",
    "    \n",
    "    def fit(self, training_data):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: shape = [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        D = self._compute_weights(training_data)\n",
    "        self.weights_ = D\n",
    "        return self\n",
    "\n",
    "    def choose_weights(self, x):\n",
    "        return self._choose_weights(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_geometry = uniform_linear_array(n_mics=10, spacing=0.5)\n",
    "microphone_array = MicrophoneArray(array_geometry)\n",
    "us = 0\n",
    "vs = compute_steering_vector_ULA(us, microphone_array)\n",
    "SNRs = np.arange(0, 31, 10)\n",
    "n_SNRs = len(SNRs)\n",
    "sigma_n = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_samples = 5000\n",
    "training_snapshots = [10, 50, 100]\n",
    "interference_powers = [10, 20, 30]\n",
    "n_interference_list = [1, 2, 3]\n",
    "# interference_powers = [20]\n",
    "# n_interference_list = [1]\n",
    "# sigma = 10**(20/10)\n",
    "training_noise_interference_data_various_snapshots = []\n",
    "for training_snapshot in training_snapshots:\n",
    "    training_noise_interference_data = []\n",
    "    for i_training_sample in range(n_training_samples):        \n",
    "        n_interferences = np.random.choice(n_interference_list)\n",
    "        nv = np.zeros((microphone_array.n_mics, training_snapshot), dtype=complex)\n",
    "        for _ in range(n_interferences):\n",
    "            u = np.random.uniform(0, 1)\n",
    "            vi = compute_steering_vector_ULA(u, microphone_array)\n",
    "            sigma = 10**(np.random.choice(interference_powers)/10)\n",
    "            ii = generate_gaussian_samples(power=sigma, shape=(1, training_snapshot))\n",
    "            nv += vi.dot(ii)\n",
    "        noise = generate_gaussian_samples(power=sigma_n, shape=(microphone_array.n_mics, training_snapshot))\n",
    "        nv += noise\n",
    "        training_noise_interference_data.append(nv)\n",
    "    training_noise_interference_data_various_snapshots.append(training_noise_interference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = []\n",
    "for i_training_snapshot in range(len(training_snapshots)):\n",
    "    training_noise_interference_data = training_noise_interference_data_various_snapshots[i_training_snapshot]\n",
    "    dictionary = BaseDLBeamformer(vs)\n",
    "    dictionary.fit(training_noise_interference_data);\n",
    "    dictionaries.append(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "snapshots = np.array([10, 20, 30, 40, 60, 100, 200, 500, 1000])\n",
    "n_snapshots = len(snapshots)\n",
    "ui1 = np.random.uniform(0, 1)\n",
    "ui2 = np.random.uniform(0, 1)\n",
    "sigma_1 = 10**(20/10)\n",
    "sigma_2 = 0*10**(20/10)\n",
    "vi1 = compute_steering_vector_ULA(ui1, microphone_array)\n",
    "vi2 = compute_steering_vector_ULA(ui2, microphone_array)\n",
    "\n",
    "n_interferences = np.random.choice(n_interference_list)\n",
    "interference_steering_vectors = []\n",
    "for _ in range(n_interferences):\n",
    "    u = np.random.uniform(0, 1)\n",
    "    vi = compute_steering_vector_ULA(u, microphone_array)\n",
    "    interference_steering_vectors.append(vi)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sinr_snr_mvdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_mpdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_baseline_mpdr = np.zeros((len(training_snapshots), n_SNRs, n_snapshots))\n",
    "\n",
    "for i_SNR in tqdm_notebook(range(n_SNRs), desc=\"SNRs\"):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())    \n",
    "    \n",
    "    for i_snapshot in tqdm_notebook(range(n_snapshots), desc=\"Snapshots\", leave=False):\n",
    "        snapshot = snapshots[i_snapshot]\n",
    "        sinr_mvdr = np.zeros(n_trials)\n",
    "        sinr_mpdr = np.zeros(n_trials)\n",
    "        sinr_baseline_mpdr = np.zeros((len(training_snapshots), n_trials))\n",
    "        \n",
    "        for i_trial in range(n_trials):\n",
    "            \n",
    "            ss = generate_gaussian_samples(power=sigma_s, shape=(1, snapshot)) # signal samples\n",
    "            nn = generate_gaussian_samples(power=sigma_n, shape=(microphone_array.n_mics, snapshot)) # Gaussian noise samples\n",
    "#             ii1 = generate_gaussian_samples(power=sigma_1, shape=(1, snapshot)) # first interference samples\n",
    "#             ii2 = generate_gaussian_samples(power=sigma_2, shape=(1, snapshot)) # second interference samples\n",
    "            nv = np.zeros((microphone_array.n_mics, snapshot), dtype=complex)\n",
    "            Rn = np.zeros((microphone_array.n_mics, microphone_array.n_mics), dtype=complex)\n",
    "            for i_interference in range(n_interferences):\n",
    "                sigma = 10**(np.random.choice(interference_powers)/10)\n",
    "                ii = generate_gaussian_samples(power=sigma, shape=(1, snapshot))\n",
    "                nv += interference_steering_vectors[i_interference].dot(ii)\n",
    "                Rn += sigma*interference_steering_vectors[i_interference].dot(interference_steering_vectors[i_interference].transpose().conjugate())\n",
    "            Rn += sigma_n*np.identity(microphone_array.n_mics)\n",
    "            Rninv = np.linalg.inv(Rn)\n",
    "            Wo = Rninv.dot(vs) / (vs.transpose().conjugate().dot(Rninv).dot(vs))\n",
    "            SINRopt = ( np.real(Wo.transpose().conjugate().dot(Rs).dot(Wo)) / np.real(Wo.transpose().conjugate().dot(Rn).dot(Wo)) )[0][0]\n",
    "            \n",
    "            nv += nn\n",
    "            sv = vs.dot(ss)\n",
    "            xx = sv + nv\n",
    "            \n",
    "            wv = compute_MVDR_weight(vs, nv)\n",
    "            wp = compute_MVDR_weight(vs, xx)\n",
    "            \n",
    "            for i_dictionary in range(len(dictionaries)):\n",
    "                dictionary = dictionaries[i_dictionary]\n",
    "                w_baseline_p = dictionary.choose_weights(xx)\n",
    "                sinr_baseline_mpdr[i_dictionary, i_trial] = np.real(w_baseline_p.transpose().conjugate().dot(Rs).dot(w_baseline_p)) / np.real(w_baseline_p.transpose().conjugate().dot(Rn).dot(w_baseline_p))\n",
    "                \n",
    "            sinr_mvdr[i_trial] = np.real(wv.transpose().conjugate().dot(Rs).dot(wv)) / np.real(wv.transpose().conjugate().dot(Rn).dot(wv))\n",
    "            sinr_mpdr[i_trial] = np.real(wp.transpose().conjugate().dot(Rs).dot(wp)) / np.real(wp.transpose().conjugate().dot(Rn).dot(wp))\n",
    "            \n",
    "        sinr_snr_mvdr[i_SNR, i_snapshot] = np.sum(sinr_mvdr) / n_trials\n",
    "        sinr_snr_mpdr[i_SNR, i_snapshot] = np.sum(sinr_mpdr) / n_trials\n",
    "        for i_dictionary in range(len(dictionaries)):\n",
    "            sinr_snr_baseline_mpdr[i_dictionary, i_SNR, i_snapshot] = np.sum(sinr_baseline_mpdr[i_dictionary, :]) / n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6*n_SNRs)); \n",
    "for i_SNR in range(n_SNRs):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())\n",
    "    \n",
    "    SINRopt = ( np.real(Wo.transpose().conjugate().dot(Rs).dot(Wo)) / np.real(Wo.transpose().conjugate().dot(Rn).dot(Wo)) )[0][0]\n",
    "    ax = fig.add_subplot(n_SNRs, 1, i_SNR+1)\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mvdr[i_SNR, :]), marker=\"o\", label=\"MVDR\")\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mpdr[i_SNR, :]), marker=\"*\", label=\"MPDR\")\n",
    "    for i_training_snapshot in range(len(training_snapshots)):\n",
    "        ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mpdr[i_training_snapshot, i_SNR, :]), \n",
    "                    label=\"Baseline - {} training snapshots\".format(training_snapshots[i_training_snapshot]))\n",
    "    ax.set_xlim(10, 1000); ax.set_ylim(-10, 45)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_xlabel(\"Number of snapshots\")\n",
    "    ax.set_ylabel(r\"$SINR_0$ [dB]\")\n",
    "    ax.set_title(\"Testing performance, {} training samples\".format(n_training_samples))\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"baseline_dl_mvdr_various_interferences.jpg\", dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-p36",
   "language": "python",
   "name": "tensorflow-gpu-p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
