{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "# print(plt.style.available)\n",
    "plt.style.use(\"ggplot\")\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import orthogonal_mp_gram\n",
    "\n",
    "def compute_steering_vector_ULA(u, microphone_array):\n",
    "    return np.exp(1j*2*np.pi*microphone_array.geometry*u).reshape((microphone_array.n_mics, 1))\n",
    "\n",
    "def compute_MVDR_weight(source_steering_vector, signals):\n",
    "    snapshot = signals.shape[1]\n",
    "    sample_covariance_matrix = signals.dot(signals.transpose().conjugate()) / snapshot\n",
    "    inverse_sample_covariance_matrix = np.linalg.inv(sample_covariance_matrix)\n",
    "    normalization_factor = (source_steering_vector.transpose().conjugate().dot(inverse_sample_covariance_matrix).dot(source_steering_vector))\n",
    "    weight = inverse_sample_covariance_matrix.dot(source_steering_vector) / normalization_factor\n",
    "    return weight\n",
    "\n",
    "def check_distortless_constraint(weight, source_steering_vector):\n",
    "    assert(np.abs(weight.transpose().conjugate().dot(source_steering_vector)) - 1 < 1e-9)\n",
    "\n",
    "def uniform_linear_array(n_mics, spacing):\n",
    "    return spacing*np.arange(-(n_mics-1)/2, (n_mics-1)/2+1).reshape(1, n_mics)\n",
    "\n",
    "def generate_gaussian_samples(power, shape):\n",
    "    return np.sqrt(power/2)*np.random.randn(shape[0], shape[1]) + 1j*np.sqrt(power/2)*np.random.randn(shape[0], shape[1]); # signal samples\n",
    "\n",
    "class MicrophoneArray():\n",
    "    def __init__(self, array_geometry):\n",
    "        self.dim = array_geometry.shape[0]\n",
    "        self.n_mics = array_geometry.shape[1]\n",
    "        self.geometry = array_geometry\n",
    "\n",
    "class BaseDLBeamformer(object):\n",
    "    def __init__(self, vs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vs: Source manifold array vector\n",
    "        \"\"\"\n",
    "        self.vs = vs\n",
    "        self.weights_ = None\n",
    "        \n",
    "    def _compute_weights(self, training_data):\n",
    "        n_training_samples = len(training_data)\n",
    "        n_mics, snapshot = training_data[0].shape\n",
    "        D = np.zeros((n_mics, n_training_samples), dtype=complex)\n",
    "        for i_training_sample in range(n_training_samples):\n",
    "            nv = training_data[i_training_sample]\n",
    "            Rnhat = nv.dot(nv.transpose().conjugate()) / snapshot\n",
    "            Rnhatinv = np.linalg.inv(Rnhat)\n",
    "            w = Rnhatinv.dot(self.vs) / (self.vs.transpose().conjugate().dot(Rnhatinv).dot(self.vs))\n",
    "            D[:, i_training_sample] = w.reshape(n_mics,)\n",
    "        return D\n",
    "\n",
    "    def _initialize(self, X):\n",
    "        pass\n",
    "\n",
    "    def _choose_weights(self, x):\n",
    "        n_dictionary_atoms = self.weights_.shape[1]\n",
    "        R = x.dot(x.transpose().conjugate())\n",
    "        proxy = np.diagonal(self.weights_.transpose().conjugate().dot(R).dot(self.weights_))\n",
    "        optimal_weight_index = np.argmin(proxy)\n",
    "\n",
    "#         min_energy = np.inf\n",
    "#         optimal_weight_index = None\n",
    "#         for i_dictionary_atom in range(n_dictionary_atoms):\n",
    "#             w = self.weights_[:, i_dictionary_atom]\n",
    "#             energy = np.real(w.transpose().conjugate().dot(R).dot(w))\n",
    "#             if min_energy > energy:\n",
    "#                 min_energy = energy\n",
    "#                 optimal_weight_index = i_dictionary_atom\n",
    "        return self.weights_[:, optimal_weight_index]\n",
    "    \n",
    "    def fit(self, training_data):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: shape = [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        D = self._compute_weights(training_data)\n",
    "        self.weights_ = D\n",
    "        return self\n",
    "\n",
    "    def choose_weights(self, x):\n",
    "        return self._choose_weights(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5\n",
    "n_mics = 10\n",
    "array_geometry = uniform_linear_array(n_mics=n_mics, spacing=d)\n",
    "microphone_array = MicrophoneArray(array_geometry)\n",
    "us = 0\n",
    "vs = compute_steering_vector_ULA(us, microphone_array)\n",
    "SNRs = np.arange(0, 31, 10)\n",
    "n_SNRs = len(SNRs)\n",
    "sigma_n = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_list = [0.29, 0.45]\n",
    "# n_training_samples = 500\n",
    "# training_snapshot = 100\n",
    "# sigma = 10**(20/10)\n",
    "# training_noise_interference_data = []\n",
    "# for i_training_sample in range(n_training_samples):\n",
    "# #     u = np.random.uniform(0, 1)\n",
    "#     u = np.random.choice(u_list)\n",
    "# #     vi = np.exp(1j*2*np.pi*d_array*u)\n",
    "#     vi = compute_steering_vector_ULA(u, microphone_array)\n",
    "#     ii = np.sqrt(sigma/2)*np.random.randn(1, training_snapshot) + 1j*np.sqrt(sigma/2)*np.random.randn(1, training_snapshot) # interference samples\n",
    "#     noise = np.sqrt(sigma_n/2)*np.random.randn(n_mics, training_snapshot) + 1j*np.sqrt(sigma_n/2)*np.random.randn(n_mics, training_snapshot) # Gaussian noise samples\n",
    "#     nv = vi*ii + noise\n",
    "#     training_noise_interference_data.append(nv)\n",
    "\n",
    "\n",
    "# training_snapshots = [100, 200, 500]\n",
    "# u_list = [0.29, 0.45]\n",
    "# interference_powers = [10]   \n",
    "# n_interference_list = [1, 2]\n",
    "\n",
    "training_snapshots = [10, 50, 100]\n",
    "interference_powers = [10, 20, 30]\n",
    "n_interference_list = [1, 2, 3]\n",
    "u_step = 0.5\n",
    "u_list = np.arange(-1, 1+1e-6, u_step)\n",
    "\n",
    "import itertools\n",
    "training_noise_interference_data_various_snapshots = []\n",
    "for training_snapshot in training_snapshots:\n",
    "    training_noise_interference_data = []\n",
    "    for n_interferences in n_interference_list:\n",
    "        interferences_params = []\n",
    "        for i_interference in range(n_interferences):\n",
    "            interference_params = list(itertools.product(*[u_list, interference_powers]))\n",
    "            interferences_params.append(interference_params)\n",
    "        interferences_param_sets = list(itertools.product(*interferences_params))        \n",
    "\n",
    "        # for param_set in interferences_param_sets:\n",
    "        for param_set in interferences_param_sets:\n",
    "            n_training_samples = 10\n",
    "            for i_training_sample in range(n_training_samples):\n",
    "                nv = np.zeros((microphone_array.n_mics, training_snapshot), dtype=complex)\n",
    "                for i_interference in range(len(param_set)):\n",
    "                    u, interference_power = param_set[i_interference]\n",
    "                    vi = compute_steering_vector_ULA(u, microphone_array)\n",
    "                    sigma = 10**(interference_power/10)\n",
    "                    ii = generate_gaussian_samples(power=sigma, shape=(1, training_snapshot))\n",
    "                    nv += vi.dot(ii)\n",
    "                noise = generate_gaussian_samples(power=sigma_n, shape=(microphone_array.n_mics, training_snapshot))\n",
    "                nv += noise\n",
    "                training_noise_interference_data.append(nv)\n",
    "    training_noise_interference_data_various_snapshots.append(training_noise_interference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train baseline dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = []\n",
    "for i_training_snapshot in range(len(training_snapshots)):\n",
    "    training_noise_interference_data = training_noise_interference_data_various_snapshots[i_training_snapshot]\n",
    "    dictionary = BaseDLBeamformer(vs)\n",
    "    dictionary.fit(training_noise_interference_data);\n",
    "    dictionaries.append(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "snapshots = np.array([10, 20, 30, 40, 60, 100, 200, 500, 1000])\n",
    "n_snapshots = len(snapshots)\n",
    "# ui1 = np.random.uniform(0, 1)\n",
    "# ui2 = np.random.uniform(0, 1)\n",
    "\n",
    "u_list = [0.29, 100]\n",
    "n_interferences_list = [len(u_list)]\n",
    "\n",
    "# Wo = Rninv.dot(vs) / (vs.transpose().conjugate().dot(Rninv).dot(vs))\n",
    "\n",
    "sinr_snr_mvdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_mpdr = np.zeros((n_SNRs, n_snapshots))\n",
    "sinr_snr_baseline_mpdr = np.zeros((len(training_snapshots), n_SNRs, n_snapshots))\n",
    "sinr_snr_baseline_mvdr = np.zeros((len(training_snapshots), n_SNRs, n_snapshots))\n",
    "\n",
    "for i_SNR in tqdm_notebook(range(n_SNRs), desc=\"SNRs\"):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())\n",
    "    \n",
    "#     SINRopt = ( np.real(Wo.transpose().conjugate().dot(Rs).dot(Wo)) / np.real(Wo.transpose().conjugate().dot(Rn).dot(Wo)) )[0][0]\n",
    "    \n",
    "    for i_snapshot in tqdm_notebook(range(n_snapshots), desc=\"Snapshots\", leave=False):\n",
    "        snapshot = snapshots[i_snapshot]\n",
    "        sinr_mvdr = np.zeros(n_trials)\n",
    "        sinr_mpdr = np.zeros(n_trials)\n",
    "        sinr_baseline_mpdr = np.zeros((len(training_snapshots), n_trials))\n",
    "        sinr_baseline_mvdr = np.zeros((len(training_snapshots), n_trials))\n",
    "        \n",
    "        for i_trial in range(n_trials):\n",
    "            ss = np.sqrt(sigma_s/2)*np.random.randn(1, snapshot) + 1j*np.sqrt(sigma_s/2)*np.random.randn(1, snapshot) # signal samples            \n",
    "            nn = np.sqrt(sigma_n/2)*np.random.randn(microphone_array.n_mics, snapshot) + 1j*np.sqrt(sigma_n/2)*np.random.randn(microphone_array.n_mics, snapshot) # Gaussian noise samples\n",
    "            \n",
    "            n_interferences = 2\n",
    "            nv = np.zeros((microphone_array.n_mics, snapshot), dtype=complex)\n",
    "            Rn = np.zeros((microphone_array.n_mics, microphone_array.n_mics), dtype=complex)\n",
    "            for i_interference in range(n_interferences):\n",
    "                u = u_list[i_interference]\n",
    "                sigma = 10**(20/10)     \n",
    "                ii = generate_gaussian_samples(power=sigma, shape=(1, snapshot))\n",
    "                interference_steering_vector = compute_steering_vector_ULA(u, microphone_array)\n",
    "                nv += interference_steering_vector*ii\n",
    "                Rn += sigma*interference_steering_vector.dot(interference_steering_vector.transpose().conjugate())\n",
    "            nv += nn\n",
    "            Rn += sigma_n*np.identity(microphone_array.n_mics)\n",
    "            Rninv = np.linalg.inv(Rn)\n",
    "\n",
    "            sv = vs*ss\n",
    "            xx = sv + nv\n",
    "            \n",
    "            for i_dictionary in range(len(dictionaries)):\n",
    "                dictionary = dictionaries[i_dictionary]\n",
    "                w_baseline_p = dictionary.choose_weights(xx)\n",
    "                sinr_baseline_mpdr[i_dictionary, i_trial] = np.real(w_baseline_p.transpose().conjugate().dot(Rs).dot(w_baseline_p)) / np.real(w_baseline_p.transpose().conjugate().dot(Rn).dot(w_baseline_p))\n",
    "                w_baseline_v = dictionary.choose_weights(nv)\n",
    "                sinr_baseline_mvdr[i_dictionary, i_trial] = np.real(w_baseline_v.transpose().conjugate().dot(Rs).dot(w_baseline_v)) / np.real(w_baseline_v.transpose().conjugate().dot(Rn).dot(w_baseline_v))                            \n",
    "                check_distortless_constraint(w_baseline_p, vs)\n",
    "                check_distortless_constraint(w_baseline_v, vs)\n",
    "            wv = compute_MVDR_weight(vs, nv)\n",
    "            wp = compute_MVDR_weight(vs, xx)\n",
    "            \n",
    "            check_distortless_constraint(wv, vs)\n",
    "            check_distortless_constraint(wp, vs)\n",
    "            \n",
    "            \n",
    "            sinr_mvdr[i_trial] = np.real(wv.transpose().conjugate().dot(Rs).dot(wv)) / np.real(wv.transpose().conjugate().dot(Rn).dot(wv))\n",
    "            sinr_mpdr[i_trial] = np.real(wp.transpose().conjugate().dot(Rs).dot(wp)) / np.real(wp.transpose().conjugate().dot(Rn).dot(wp))\n",
    "#             sinr_baseline_mpdr[i_trial] = np.real(w_baseline_p.transpose().conjugate().dot(Rs).dot(w_baseline_p)) / np.real(w_baseline_p.transpose().conjugate().dot(Rn).dot(w_baseline_p))\n",
    "#             sinr_baseline_mvdr[i_trial] = np.real(w_baseline_v.transpose().conjugate().dot(Rs).dot(w_baseline_v)) / np.real(w_baseline_v.transpose().conjugate().dot(Rn).dot(w_baseline_v))\n",
    "        sinr_snr_mvdr[i_SNR, i_snapshot] = np.sum(sinr_mvdr) / n_trials\n",
    "        sinr_snr_mpdr[i_SNR, i_snapshot] = np.sum(sinr_mpdr) / n_trials\n",
    "#         sinr_snr_baseline_mpdr[i_SNR, i_snapshot] = np.sum(sinr_baseline_mpdr) / n_trials    \n",
    "#         sinr_snr_baseline_mvdr[i_SNR, i_snapshot] = np.sum(sinr_baseline_mvdr) / n_trials    \n",
    "        for i_dictionary in range(len(dictionaries)):\n",
    "            sinr_snr_baseline_mpdr[i_dictionary, i_SNR, i_snapshot] = np.sum(sinr_baseline_mpdr[i_dictionary, :]) / n_trials\n",
    "            sinr_snr_baseline_mvdr[i_dictionary, i_SNR, i_snapshot] = np.sum(sinr_baseline_mvdr[i_dictionary, :]) / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6*n_SNRs)); \n",
    "for i_SNR in range(n_SNRs):\n",
    "    sigma_s = 10**(SNRs[i_SNR] / 10)\n",
    "    Rs = sigma_s * vs.dot(vs.transpose().conjugate())\n",
    "    ax = fig.add_subplot(n_SNRs, 1, i_SNR+1)\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mpdr[i_SNR, :]), marker=\"o\", alpha=0.3, label=\"MPDR\")\n",
    "    ax.semilogx(snapshots, 10*np.log10(sinr_snr_mvdr[i_SNR, :]), marker=\"*\", alpha=0.3, label=\"MVDR\")\n",
    "#     ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mpdr[i_SNR, :]))\n",
    "#     ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mvdr[i_SNR, :]))\n",
    "    for i_training_snapshot in range(len(training_snapshots)):\n",
    "        ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mpdr[i_training_snapshot, i_SNR, :]), \n",
    "                    label=\"Baseline MPDR - {} training snapshots\".format(training_snapshots[i_training_snapshot]))\n",
    "        ax.semilogx(snapshots, 10*np.log10(sinr_snr_baseline_mvdr[i_training_snapshot, i_SNR, :]), \n",
    "                    label=\"Baseline MVDR - {} training snapshots\".format(training_snapshots[i_training_snapshot]))\n",
    "    ax.legend()\n",
    "    ax.set_xlim(10, 1000); ax.set_ylim(-10, 45);\n",
    "    ax.set_xlabel(\"Number of snapshots\");\n",
    "    ax.set_ylabel(r\"$SINR_0$ [dB]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Python 3.6",
   "language": "python",
   "name": "tf-p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
