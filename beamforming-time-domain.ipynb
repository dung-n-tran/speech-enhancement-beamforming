{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The direct SNR for good source is 13.711335826786922\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'warnings' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3ac4fab1094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0mplot_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Desired Signal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c3ac4fab1094>\u001b[0m in \u001b[0;36mplot_spectrogram\u001b[0;34m(F, title)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     pra.spectroplot(F.T, fft_size+fft_zp, fft_hop, Fs, vmin=vmin, vmax=vmax,\n\u001b[0;32m--> 227\u001b[0;31m             cmap=plt.get_cmap(cmap), interpolation=interpolation, colorbar=False)\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml-p36/lib/python3.6/site-packages/pyroomacoustics/stft.py\u001b[0m in \u001b[0;36mspectroplot\u001b[0;34m(Z, N, hop, fs, fdiv, tdiv, vmin, vmax, cmap, interpolation, colorbar)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 vmin=None, vmax=None, cmap=None, interpolation='none', colorbar=True):\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     warnings.warn(\"The function pyroomacoustics.spectroplot is deprecated and will disappear soon.\",\n\u001b[0m\u001b[1;32m     56\u001b[0m             DeprecationWarning)\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'warnings' referenced before assignment"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a longer example that applies time domain beamforming towards a source\n",
    "of interest in the presence of a strong interfering source.\n",
    "'''\n",
    "\n",
    "# from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import pyroomacoustics as pra\n",
    "\n",
    "# Spectrogram figure properties\n",
    "figsize=(15, 7)        # figure size\n",
    "fft_size = 512         # fft size for analysis\n",
    "fft_hop  = 8           # hop between analysis frame\n",
    "fft_zp = 512           # zero padding\n",
    "analysis_window = np.concatenate((pra.hann(fft_size), np.zeros(fft_zp)))\n",
    "t_cut = 0.83           # length in [s] to remove at end of signal (no sound)\n",
    "\n",
    "# Some simulation parameters\n",
    "Fs = 8000\n",
    "t0 = 1./(Fs*np.pi*1e-2)  # starting time function of sinc decay in RIR response\n",
    "absorption = 0.1\n",
    "max_order_sim = 2\n",
    "sigma2_n = 5e-7\n",
    "\n",
    "# Microphone array design parameters\n",
    "mic1 = np.array([2, 1.5])   # position\n",
    "M = 8                       # number of microphones\n",
    "d = 0.08                    # distance between microphones\n",
    "phi = 0.                    # angle from horizontal\n",
    "max_order_design = 1        # maximum image generation used in design\n",
    "shape = 'Linear'            # array shape\n",
    "Lg_t = 0.100                # Filter size in seconds\n",
    "Lg = np.ceil(Lg_t*Fs)       # Filter size in samples\n",
    "delay = 0.050               # Beamformer delay in seconds\n",
    "\n",
    "# Define the FFT length\n",
    "N = 1024\n",
    "\n",
    "# Create a microphone array\n",
    "if shape is 'Circular':\n",
    "    R = pra.circular_2D_array(mic1, M, phi, d*M/(2*np.pi)) \n",
    "else:\n",
    "    R = pra.linear_2D_array(mic1, M, phi, d) \n",
    "\n",
    "# path to samples\n",
    "# path = os.path.dirname(__file__)\n",
    "path = './'\n",
    "# The first signal (of interest) is singing\n",
    "rate1, signal1 = wavfile.read(path + '/input_samples/singing_'+str(Fs)+'.wav')\n",
    "signal1 = np.array(signal1, dtype=float)\n",
    "signal1 = pra.normalize(signal1)\n",
    "signal1 = pra.highpass(signal1, Fs)\n",
    "delay1 = 0.\n",
    "\n",
    "# The second signal (interferer) is some german speech\n",
    "rate2, signal2 = wavfile.read(path + '/input_samples/german_speech_'+str(Fs)+'.wav')\n",
    "signal2 = np.array(signal2, dtype=float)\n",
    "signal2 = pra.normalize(signal2)\n",
    "signal2 = pra.highpass(signal2, Fs)\n",
    "delay2 = 1.\n",
    "\n",
    "# Create the room\n",
    "room_dim = [4, 6]\n",
    "room1 = pra.ShoeBox(\n",
    "    room_dim,\n",
    "    absorption=absorption,\n",
    "    fs=Fs,\n",
    "    t0=t0,\n",
    "    max_order=max_order_sim,\n",
    "    sigma2_awgn=sigma2_n)\n",
    "\n",
    "# Add sources to room\n",
    "good_source = np.array([1, 4.5])           # good source\n",
    "normal_interferer = np.array([2.8, 4.3])   # interferer\n",
    "room1.add_source(good_source, signal=signal1, delay=delay1)\n",
    "room1.add_source(normal_interferer, signal=signal2, delay=delay2)\n",
    "\n",
    "'''\n",
    "MVDR direct path only simulation\n",
    "'''\n",
    "\n",
    "# compute beamforming filters\n",
    "mics = pra.Beamformer(R, Fs, N=N, Lg=Lg)\n",
    "room1.add_microphone_array(mics)\n",
    "room1.compute_rir()\n",
    "room1.simulate()\n",
    "mics.rake_mvdr_filters(room1.sources[0][0:1],\n",
    "                    room1.sources[1][0:1],\n",
    "                    sigma2_n*np.eye(mics.Lg*mics.M), delay=delay)\n",
    "\n",
    "# process the signal\n",
    "output = mics.process()\n",
    "\n",
    "# save to output file\n",
    "input_mic = pra.normalize(pra.highpass(mics.signals[mics.M//2], Fs))\n",
    "wavfile.write(path + '/output_samples/input.wav', Fs, input_mic)\n",
    "\n",
    "out_DirectMVDR = pra.normalize(pra.highpass(output, Fs))\n",
    "wavfile.write(path + '/output_samples/output_DirectMVDR.wav', Fs, out_DirectMVDR)\n",
    "\n",
    "\n",
    "'''\n",
    "Rake MVDR simulation\n",
    "'''\n",
    "\n",
    "# Add the microphone array and compute RIR\n",
    "mics = pra.Beamformer(R, Fs, N, Lg=Lg)\n",
    "room1.add_microphone_array(mics)\n",
    "room1.compute_rir()\n",
    "room1.simulate()\n",
    "\n",
    "# Design the beamforming filters using some of the images sources\n",
    "good_sources = room1.sources[0][:max_order_design+1]\n",
    "bad_sources = room1.sources[1][:max_order_design+1]\n",
    "mics.rake_mvdr_filters(good_sources, \n",
    "                    bad_sources, \n",
    "                    sigma2_n*np.eye(mics.Lg*mics.M), delay=delay)\n",
    "\n",
    "# process the signal\n",
    "output = mics.process()\n",
    "\n",
    "# save to output file\n",
    "out_RakeMVDR = pra.normalize(pra.highpass(output, Fs))\n",
    "wavfile.write(path + '/output_samples/output_RakeMVDR.wav', Fs, out_RakeMVDR)\n",
    "\n",
    "'''\n",
    "Perceptual direct path only simulation\n",
    "'''\n",
    "\n",
    "# compute beamforming filters\n",
    "mics = pra.Beamformer(R, Fs, N, Lg=Lg)\n",
    "room1.add_microphone_array(mics)\n",
    "room1.compute_rir()\n",
    "room1.simulate()\n",
    "mics.rake_perceptual_filters(room1.sources[0][0:1],\n",
    "        room1.sources[1][0:1],\n",
    "                    sigma2_n*np.eye(mics.Lg*mics.M), delay=delay)\n",
    "\n",
    "# process the signal\n",
    "output = mics.process()\n",
    "\n",
    "# save to output file\n",
    "out_DirectPerceptual = pra.normalize(pra.highpass(output, Fs))\n",
    "wavfile.write(path + '/output_samples/output_DirectPerceptual.wav', Fs, out_DirectPerceptual)\n",
    "\n",
    "'''\n",
    "Rake Perceptual simulation\n",
    "'''\n",
    "\n",
    "# compute beamforming filters\n",
    "mics = pra.Beamformer(R, Fs, N, Lg=Lg)\n",
    "room1.add_microphone_array(mics)\n",
    "room1.compute_rir()\n",
    "room1.simulate()\n",
    "mics.rake_perceptual_filters(good_sources, \n",
    "                    bad_sources, \n",
    "                    sigma2_n*np.eye(mics.Lg*mics.M), delay=delay)\n",
    "\n",
    "# process the signal\n",
    "output = mics.process()\n",
    "\n",
    "# save to output file\n",
    "out_RakePerceptual = pra.normalize(pra.highpass(output, Fs))\n",
    "wavfile.write(path + '/output_samples/output_RakePerceptual.wav', Fs, out_RakePerceptual)\n",
    "\n",
    "'''\n",
    "Plot all the spectrogram\n",
    "'''\n",
    "\n",
    "dSNR = pra.dB(room1.direct_snr(mics.center[:,0], source=0), power=True)\n",
    "print('The direct SNR for good source is ' + str(dSNR))\n",
    "\n",
    "# remove a bit of signal at the end\n",
    "n_lim = int(np.ceil(len(input_mic) - t_cut*Fs))\n",
    "input_clean = signal1[:n_lim]\n",
    "input_mic = input_mic[:n_lim]\n",
    "out_DirectMVDR = out_DirectMVDR[:n_lim]\n",
    "out_RakeMVDR = out_RakeMVDR[:n_lim]\n",
    "out_DirectPerceptual = out_DirectPerceptual[:n_lim]\n",
    "out_RakePerceptual = out_RakePerceptual[:n_lim]\n",
    "\n",
    "\n",
    "# compute time-frequency planes\n",
    "F0 = pra.stft(input_clean, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "F1 = pra.stft(input_mic, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "F2 = pra.stft(out_DirectMVDR, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "F3 = pra.stft(out_RakeMVDR, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "F4 = pra.stft(out_DirectPerceptual, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "F5 = pra.stft(out_RakePerceptual, fft_size, fft_hop, \n",
    "          win=analysis_window, \n",
    "          zp_back=fft_zp)\n",
    "\n",
    "# (not so) fancy way to set the scale to avoid having the spectrum\n",
    "# dominated by a few outliers\n",
    "p_min = 7\n",
    "p_max = 100\n",
    "all_vals = np.concatenate((pra.dB(F1+pra.eps), \n",
    "                           pra.dB(F2+pra.eps), \n",
    "                           pra.dB(F3+pra.eps),\n",
    "                           pra.dB(F0+pra.eps),\n",
    "                           pra.dB(F4+pra.eps),\n",
    "                           pra.dB(F5+pra.eps))).flatten()\n",
    "vmin, vmax = np.percentile(all_vals, [p_min, p_max])\n",
    "\n",
    "cmap = 'afmhot'\n",
    "interpolation='none'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize, nrows=2, ncols=3)\n",
    "\n",
    "def plot_spectrogram(F, title):\n",
    "    pra.spectroplot(F.T, fft_size+fft_zp, fft_hop, Fs, vmin=vmin, vmax=vmax,\n",
    "            cmap=plt.get_cmap(cmap), interpolation=interpolation, colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.axis('off')\n",
    "\n",
    "ax = plt.subplot(2,3,1)\n",
    "plot_spectrogram(F0, 'Desired Signal')\n",
    "\n",
    "ax = plt.subplot(2,3,4)\n",
    "plot_spectrogram(F1, 'Microphone Input')\n",
    "\n",
    "ax = plt.subplot(2,3,2)\n",
    "plot_spectrogram(F2, 'Direct MVDR')\n",
    "\n",
    "ax = plt.subplot(2,3,5)\n",
    "plot_spectrogram(F3, 'Rake MVDR')\n",
    "\n",
    "ax = plt.subplot(2,3,3)\n",
    "plot_spectrogram(F4, 'Direct Perceptual')\n",
    "\n",
    "ax = plt.subplot(2,3,6)\n",
    "plot_spectrogram(F5, 'Rake Perceptual')\n",
    "\n",
    "fig.savefig(path + '/figures/spectrograms.png', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-180f1201419f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Python 3.6",
   "language": "python",
   "name": "tf-p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
